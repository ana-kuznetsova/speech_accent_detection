{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "failed_attempts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b62cc1957ec4fdf83e1c9af0141dd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9509803ded3e4f6ebc4fbfc81c07dce3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05d9ef81171540d7875659d3ebe6006c",
              "IPY_MODEL_f5db84884967487eb129c091cfe2216b"
            ]
          }
        },
        "9509803ded3e4f6ebc4fbfc81c07dce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05d9ef81171540d7875659d3ebe6006c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fe2607461b148fbb89ae10ffeb1c12d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 2442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af86c0c417e6448e995adebd4a7eada0"
          }
        },
        "f5db84884967487eb129c091cfe2216b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4c9362c70274dec94715e9351563496",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 2442/2442 [00:04&lt;00:00, 505.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d474cf8d26a4b1eb524e12d75629c0b"
          }
        },
        "7fe2607461b148fbb89ae10ffeb1c12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af86c0c417e6448e995adebd4a7eada0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4c9362c70274dec94715e9351563496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d474cf8d26a4b1eb524e12d75629c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYI9mlm2Xyy7",
        "colab_type": "code",
        "outputId": "7f6ba11c-0e93-4f6a-83ce-a98bbba1833d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import hickle as h\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cutRsydhUEhE",
        "colab_type": "code",
        "outputId": "216623d9-006c-4e36-c4d0-9d77e455729c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBqYkXUk5I_0",
        "colab_type": "code",
        "outputId": "317f1b36-a3bb-44f5-9f10-d7b248153908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install hickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hickle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/45/ebc9e2a77f2349a4947a2eedd4480fc7b248d3f315b0f5a3a1826adcc522/hickle-3.4.5-py3-none-any.whl (40kB)\n",
            "\r\u001b[K     |████████▏                       | 10kB 32.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from hickle) (2.8.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from hickle) (0.3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hickle) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->hickle) (1.12.0)\n",
            "Installing collected packages: hickle\n",
            "Successfully installed hickle-3.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghfzvxSfoACU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mfccs = h.load('drive/My Drive/mfcc.hkl')\n",
        "#pitches = h.load('drive/My Drive/pitches.hkl')\n",
        "deltas = h.load('drive/My Drive/deltas.hkl')\n",
        "ddeltas = h.load('drive/My Drive/deltas.hkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOWKBsrbp51a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mfccs = [np.nan_to_num(m.T) for m in mfccs]\n",
        "deltas = [np.nan_to_num(d.T) for d in deltas]\n",
        "ddeltas = [np.nan_to_num(dd.T) for dd in ddeltas]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTQjfZKfX8UG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_max(egs):\n",
        "        return max([e.shape[0] for e in egs])\n",
        "    \n",
        "def pad_mfcc(egs):\n",
        "    \n",
        "    max_val = find_max(egs)\n",
        "\n",
        "    padded = np.array([np.pad(e, ((0, max_val-e.shape[0]), (0, 0)) , 'constant') for e in egs])\n",
        "    return padded    \n",
        "\n",
        "def pad_pitch(egs):\n",
        "    max_val = find_max(egs)\n",
        "\n",
        "    padded = np.array([np.pad(e, (0, max_val-e.shape[0]) , 'constant') for e in egs])\n",
        "    return padded "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF8sNg0IYHMI",
        "colab_type": "code",
        "outputId": "e1a9c22e-5ac3-443d-c710-1367b83f5c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mfccs = pad_mfcc(mfccs)\n",
        "deltas = pad_mfcc(deltas)\n",
        "ddeltas = pad_mfcc(ddeltas)\n",
        "\n",
        "data = np.array([[i,j,k] for i, j, k in zip(mfccs, deltas, ddeltas)])\n",
        "data = data.reshape(2432, 5388, 20, 3)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2432, 5388, 20, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-dp7OkLcfq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(mfccs)\n",
        "del(deltas)\n",
        "del(ddeltas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JZU-gZHJxxe",
        "colab_type": "code",
        "outputId": "94b9b9a9-9893-44f7-e256-bc402658e6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2b62cc1957ec4fdf83e1c9af0141dd33",
            "9509803ded3e4f6ebc4fbfc81c07dce3",
            "05d9ef81171540d7875659d3ebe6006c",
            "f5db84884967487eb129c091cfe2216b",
            "7fe2607461b148fbb89ae10ffeb1c12d",
            "af86c0c417e6448e995adebd4a7eada0",
            "e4c9362c70274dec94715e9351563496",
            "1d474cf8d26a4b1eb524e12d75629c0b"
          ]
        }
      },
      "source": [
        "from tqdm import  tqdm_notebook\n",
        "labels = np.zeros((2432,2))\n",
        "path = \"drive/My Drive/train_labels\"\n",
        "folder = os.fsencode(path)\n",
        "for file in tqdm_notebook(os.listdir(folder)):\n",
        "  fn = os.fsdecode(file)\n",
        "  try:\n",
        "    ind = int(fn.split('.')[0])\n",
        "  except:\n",
        "    ind = int(fn.split('.')[0].split()[0])\n",
        "  labels[ind] = np.load(path +\"/\"+fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b62cc1957ec4fdf83e1c9af0141dd33",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2442), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlhWXOfLqQeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train = pd.read_csv('drive/My Drive/train.tsv', sep='\\t')\n",
        "#num_speakers = len(set(train['client_id']))\n",
        "#spk = list(set(train['client_id']))\n",
        "#mapped = {spk[i]:i for i in range(num_speakers)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DUgKZEHsn40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train = train.replace(mapped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwWC-EAOYKOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get speaker IDs\n",
        "#spkIDs = np.array(train['client_id'].values).reshape(-1,1)\n",
        "#del(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp5h3HuxYLEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PARAMS\n",
        "\n",
        "#TEMP_DIM_MAX1 = find_max(mfccs)\n",
        "NUM_MFCCS = 20\n",
        "BATCH_SIZE = 120\n",
        "\n",
        "#TEMP_DIM_MAX2 = find_max(pitches)\n",
        "NUM_HIDDEN = 128 #Number of hidden units\n",
        "#NUM_SPK = len(spkIDs)\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_DZts93YOO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, return_seq=True):\n",
        "        super().__init__()\n",
        "        initializer = tf.variance_scaling_initializer(scale = 2.0)\n",
        "        self.l1 = keras.layers.LSTM(hidden_size, activation=tf.nn.tanh,\n",
        "                                    kernel_initializer=initializer, \n",
        "                                    return_sequences=return_seq)\n",
        "        \n",
        "    def call(self, x):\n",
        "        l = self.l1(x)\n",
        "        return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoB7d27l_Mcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array([(i,j) for i, j in zip(data, labels)])\n",
        "np.random.shuffle(data)\n",
        "#mfccs_pad = np.array([i[0] for i in data])\n",
        "#spkIDs = np.array([i[1] for i in data])\n",
        "labels = np.array([i[1] for i in data])\n",
        "data = np.array([i[0] for i in data])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VmxzEPxd6vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.argmax(labels, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-rUvvi9jsK2",
        "colab_type": "code",
        "outputId": "a9831e4e-0867-4f6c-cfd0-28c48d2ce8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2432,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRHk3eXEePO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.reshape((2432, 20, 5388, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94p-4G5iYSZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_lstm(train, ytrain, test, ytest, num_epochs, batchsize):\n",
        "    \n",
        "    #Run model\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    X = tf.placeholder(tf.float32, [None, 20, train.shape[2]])\n",
        "    y = tf.placeholder(tf.int32, [None]) \n",
        "    \n",
        "    l1m = LSTM(NUM_HIDDEN)\n",
        "    l1m_out = l1m(X)\n",
        "    l1m_out = tf.layers.Dropout(0.4)(l1m_out)\n",
        "    l2m = LSTM(NUM_HIDDEN, return_seq=False)\n",
        "    l2m_out = l2m(l1m_out)\n",
        "    l2m_out = tf.layers.Dropout(0.4)(l2m_out)\n",
        "    output = tf.layers.dense(l2m_out, 100)\n",
        "    \n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
        "    soft_out = tf.nn.softmax(output)\n",
        "    \n",
        "    y_onehot = tf.one_hot(y, 2)\n",
        "    \n",
        "    pred = tf.equal(tf.argmax(soft_out,1), tf.argmax(y_onehot,1))\n",
        "    #pred = tf.equal(tf.argmax(soft_out,1), y)\n",
        "    accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
        "    hist = {'train_loss':[], 'test_loss':[], 'train_acc':[], 'test_acc':[]}\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      steps = train.shape[0]//batchsize\n",
        "      for epoch in range(num_epochs):\n",
        "          epoch_loss = 0\n",
        "          epoch_acc = 0\n",
        "          for step in range(steps):\n",
        "              start = step*batchsize\n",
        "              end = min(start + batchsize, train.shape[0])\n",
        "              batch_mfcc = train[start:end]\n",
        "              #batch_pitch = pitches[start:end]\n",
        "              batchy = ytrain[start:end]\n",
        "              _, cost = sess.run([optimizer, loss], feed_dict={X:batch_mfcc, \n",
        "                                                                y:batchy})\n",
        "              train_acc = sess.run(accuracy, feed_dict = {X:batch_mfcc, \n",
        "                                                          y:batchy})\n",
        "              epoch_loss += cost\n",
        "              epoch_acc += train_acc\n",
        "              \n",
        "              print(\"Epoch:\",epoch,\"Step:\",step+1,\"TrainLoss:\",epoch_loss/(step+1))\n",
        "          train_loss, train_acc = sess.run([loss,accuracy], feed_dict={X:train,y:ytrain})\n",
        "          print(\"Epoch:\",epoch,\"Loss:\", train_loss, \"accuracy:\", train_acc)\n",
        "          test_loss, test_acc = sess.run([loss,accuracy], feed_dict = {X:test, y:ytest})\n",
        "          print(\"Test:\",\"Epoch:\",epoch,\"Loss:\", test_loss, \"accuracy:\", test_acc)\n",
        "          hist['train_loss'].append(train_loss)\n",
        "          hist['train_acc'].append(train_acc)\n",
        "          hist['test_loss'].append(test_loss)\n",
        "          hist['test_acc'].append(test_acc)\n",
        "    return hist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7po6fi9YV3o",
        "colab_type": "code",
        "outputId": "40ac19c3-2870-4690-931c-30eafd79e996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train, ytrain, test, ytest, num_epochs, batchsize\n",
        "\n",
        "hist = run_lstm(data[:1500], labels[:1500], data[1500:], labels[1500:], 10, 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Step: 1 TrainLoss: 0.6919435262680054\n",
            "Epoch: 0 Step: 2 TrainLoss: 0.6850835084915161\n",
            "Epoch: 0 Step: 3 TrainLoss: 0.6908437410990397\n",
            "Epoch: 0 Step: 4 TrainLoss: 0.692546159029007\n",
            "Epoch: 0 Step: 5 TrainLoss: 0.6998616576194763\n",
            "Epoch: 0 Step: 6 TrainLoss: 0.7023633023103079\n",
            "Epoch: 0 Step: 7 TrainLoss: 0.7022409268787929\n",
            "Epoch: 0 Step: 8 TrainLoss: 0.7031664103269577\n",
            "Epoch: 0 Step: 9 TrainLoss: 0.7026065720452203\n",
            "Epoch: 0 Step: 10 TrainLoss: 0.7039028763771057\n",
            "Epoch: 0 Step: 11 TrainLoss: 0.7051765864545648\n",
            "Epoch: 0 Loss: 0.42264774 accuracy: 0.936\n",
            "Test: Epoch: 0 Loss: 0.6974143 accuracy: 0.52896994\n",
            "Epoch: 1 Step: 1 TrainLoss: 0.38037627935409546\n",
            "Epoch: 1 Step: 2 TrainLoss: 0.3592494875192642\n",
            "Epoch: 1 Step: 3 TrainLoss: 0.3442332446575165\n",
            "Epoch: 1 Step: 4 TrainLoss: 0.3239079490303993\n",
            "Epoch: 1 Step: 5 TrainLoss: 0.3021161943674088\n",
            "Epoch: 1 Step: 6 TrainLoss: 0.2853999709089597\n",
            "Epoch: 1 Step: 7 TrainLoss: 0.2729417915855135\n",
            "Epoch: 1 Step: 8 TrainLoss: 0.2650747410953045\n",
            "Epoch: 1 Step: 9 TrainLoss: 0.25574419564670986\n",
            "Epoch: 1 Step: 10 TrainLoss: 0.2512039840221405\n",
            "Epoch: 1 Step: 11 TrainLoss: 0.2465529807589271\n",
            "Epoch: 1 Loss: 0.08003625 accuracy: 0.968\n",
            "Test: Epoch: 1 Loss: 1.0232072 accuracy: 0.51609445\n",
            "Epoch: 2 Step: 1 TrainLoss: 0.015725962817668915\n",
            "Epoch: 2 Step: 2 TrainLoss: 0.014743918552994728\n",
            "Epoch: 2 Step: 3 TrainLoss: 0.01476126971344153\n",
            "Epoch: 2 Step: 4 TrainLoss: 0.013799244537949562\n",
            "Epoch: 2 Step: 5 TrainLoss: 0.012446513958275318\n",
            "Epoch: 2 Step: 6 TrainLoss: 0.012983897545685371\n",
            "Epoch: 2 Step: 7 TrainLoss: 0.012256760815424579\n",
            "Epoch: 2 Step: 8 TrainLoss: 0.011410546663682908\n",
            "Epoch: 2 Step: 9 TrainLoss: 0.010737197370164923\n",
            "Epoch: 2 Step: 10 TrainLoss: 0.009914790606126189\n",
            "Epoch: 2 Step: 11 TrainLoss: 0.00918979515236887\n",
            "Epoch: 2 Loss: 0.10085562 accuracy: 0.97066665\n",
            "Test: Epoch: 2 Loss: 1.8169001 accuracy: 0.49248928\n",
            "Epoch: 3 Step: 1 TrainLoss: 0.0022629990708082914\n",
            "Epoch: 3 Step: 2 TrainLoss: 0.0018892493098974228\n",
            "Epoch: 3 Step: 3 TrainLoss: 0.0016218112626423438\n",
            "Epoch: 3 Step: 4 TrainLoss: 0.0014184593601385131\n",
            "Epoch: 3 Step: 5 TrainLoss: 0.0012745049665682019\n",
            "Epoch: 3 Step: 6 TrainLoss: 0.0011594698977811884\n",
            "Epoch: 3 Step: 7 TrainLoss: 0.0010724541581501918\n",
            "Epoch: 3 Step: 8 TrainLoss: 0.0010062025394290686\n",
            "Epoch: 3 Step: 9 TrainLoss: 0.0009449126664549112\n",
            "Epoch: 3 Step: 10 TrainLoss: 0.0008976753626484424\n",
            "Epoch: 3 Step: 11 TrainLoss: 0.000859336752910167\n",
            "Epoch: 3 Loss: 0.1296449 accuracy: 0.97\n",
            "Test: Epoch: 3 Loss: 2.3007202 accuracy: 0.5075107\n",
            "Epoch: 4 Step: 1 TrainLoss: 0.0005530560738407075\n",
            "Epoch: 4 Step: 2 TrainLoss: 0.0005007603904232383\n",
            "Epoch: 4 Step: 3 TrainLoss: 0.0005089563007156054\n",
            "Epoch: 4 Step: 4 TrainLoss: 0.0004734150134027004\n",
            "Epoch: 4 Step: 5 TrainLoss: 0.0004465171019546688\n",
            "Epoch: 4 Step: 6 TrainLoss: 0.00042166623946589726\n",
            "Epoch: 4 Step: 7 TrainLoss: 0.00040212529295656296\n",
            "Epoch: 4 Step: 8 TrainLoss: 0.0003885876212734729\n",
            "Epoch: 4 Step: 9 TrainLoss: 0.0003729797705697517\n",
            "Epoch: 4 Step: 10 TrainLoss: 0.00036241930502001196\n",
            "Epoch: 4 Step: 11 TrainLoss: 0.0003546555394264446\n",
            "Epoch: 4 Loss: 0.14520599 accuracy: 0.96933335\n",
            "Test: Epoch: 4 Loss: 2.5418372 accuracy: 0.5075107\n",
            "Epoch: 5 Step: 1 TrainLoss: 0.00034665889688767493\n",
            "Epoch: 5 Step: 2 TrainLoss: 0.00031663940171711147\n",
            "Epoch: 5 Step: 3 TrainLoss: 0.00032670456372822326\n",
            "Epoch: 5 Step: 4 TrainLoss: 0.0003066211938858032\n",
            "Epoch: 5 Step: 5 TrainLoss: 0.0002914103766670451\n",
            "Epoch: 5 Step: 6 TrainLoss: 0.0002773078134244618\n",
            "Epoch: 5 Step: 7 TrainLoss: 0.0002662578294153458\n",
            "Epoch: 5 Step: 8 TrainLoss: 0.00025887049741868395\n",
            "Epoch: 5 Step: 9 TrainLoss: 0.0002499461649373795\n",
            "Epoch: 5 Step: 10 TrainLoss: 0.0002443063480313867\n",
            "Epoch: 5 Step: 11 TrainLoss: 0.00024037115508690476\n",
            "Epoch: 5 Loss: 0.15239245 accuracy: 0.96933335\n",
            "Test: Epoch: 5 Loss: 2.6475918 accuracy: 0.5107296\n",
            "Epoch: 6 Step: 1 TrainLoss: 0.00026087084552273154\n",
            "Epoch: 6 Step: 2 TrainLoss: 0.00024019724514801055\n",
            "Epoch: 6 Step: 3 TrainLoss: 0.0002455130355277409\n",
            "Epoch: 6 Step: 4 TrainLoss: 0.0002316960453754291\n",
            "Epoch: 6 Step: 5 TrainLoss: 0.0002214806794654578\n",
            "Epoch: 6 Step: 6 TrainLoss: 0.0002118285143903146\n",
            "Epoch: 6 Step: 7 TrainLoss: 0.00020444507078666772\n",
            "Epoch: 6 Step: 8 TrainLoss: 0.0001995738912228262\n",
            "Epoch: 6 Step: 9 TrainLoss: 0.0001935370350515263\n",
            "Epoch: 6 Step: 10 TrainLoss: 0.00018987812654813752\n",
            "Epoch: 6 Step: 11 TrainLoss: 0.00018735059579326347\n",
            "Epoch: 6 Loss: 0.15615997 accuracy: 0.96933335\n",
            "Test: Epoch: 6 Loss: 2.699565 accuracy: 0.5107296\n",
            "Epoch: 7 Step: 1 TrainLoss: 0.00021569975069724023\n",
            "Epoch: 7 Step: 2 TrainLoss: 0.0001994101403397508\n",
            "Epoch: 7 Step: 3 TrainLoss: 0.00020115787143974254\n",
            "Epoch: 7 Step: 4 TrainLoss: 0.0001903581687656697\n",
            "Epoch: 7 Step: 5 TrainLoss: 0.0001826938067097217\n",
            "Epoch: 7 Step: 6 TrainLoss: 0.00017532693406489366\n",
            "Epoch: 7 Step: 7 TrainLoss: 0.00016985515581576953\n",
            "Epoch: 7 Step: 8 TrainLoss: 0.0001662563099671388\n",
            "Epoch: 7 Step: 9 TrainLoss: 0.00016173733456525952\n",
            "Epoch: 7 Step: 10 TrainLoss: 0.00015904955798760057\n",
            "Epoch: 7 Step: 11 TrainLoss: 0.00015716327735307542\n",
            "Epoch: 7 Loss: 0.15875909 accuracy: 0.96933335\n",
            "Test: Epoch: 7 Loss: 2.7345843 accuracy: 0.51180255\n",
            "Epoch: 8 Step: 1 TrainLoss: 0.00018840251141227782\n",
            "Epoch: 8 Step: 2 TrainLoss: 0.0001740257503115572\n",
            "Epoch: 8 Step: 3 TrainLoss: 0.00017352587989686677\n",
            "Epoch: 8 Step: 4 TrainLoss: 0.00016433687414973974\n",
            "Epoch: 8 Step: 5 TrainLoss: 0.00015806349110789598\n",
            "Epoch: 8 Step: 6 TrainLoss: 0.00015196989746376252\n",
            "Epoch: 8 Step: 7 TrainLoss: 0.000147583288448264\n",
            "Epoch: 8 Step: 8 TrainLoss: 0.00014467705204879167\n",
            "Epoch: 8 Step: 9 TrainLoss: 0.00014103644288196746\n",
            "Epoch: 8 Step: 10 TrainLoss: 0.00013887558088754304\n",
            "Epoch: 8 Step: 11 TrainLoss: 0.00013731121792013502\n",
            "Epoch: 8 Loss: 0.16085833 accuracy: 0.96933335\n",
            "Test: Epoch: 8 Loss: 2.7635756 accuracy: 0.51180255\n",
            "Epoch: 9 Step: 1 TrainLoss: 0.0001686363248154521\n",
            "Epoch: 9 Step: 2 TrainLoss: 0.0001555212656967342\n",
            "Epoch: 9 Step: 3 TrainLoss: 0.00015372733954185\n",
            "Epoch: 9 Step: 4 TrainLoss: 0.0001456524660170544\n",
            "Epoch: 9 Step: 5 TrainLoss: 0.00014026414719410242\n",
            "Epoch: 9 Step: 6 TrainLoss: 0.00013499000609347908\n",
            "Epoch: 9 Step: 7 TrainLoss: 0.00013130594223704456\n",
            "Epoch: 9 Step: 8 TrainLoss: 0.00012883618364867289\n",
            "Epoch: 9 Step: 9 TrainLoss: 0.00012576593306019076\n",
            "Epoch: 9 Step: 10 TrainLoss: 0.00012393799261189997\n",
            "Epoch: 9 Step: 11 TrainLoss: 0.00012256777369078588\n",
            "Epoch: 9 Loss: 0.16275948 accuracy: 0.9686667\n",
            "Test: Epoch: 9 Loss: 2.790759 accuracy: 0.51287556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd-ypCBXmN9j",
        "colab_type": "text"
      },
      "source": [
        "## Monster LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua9aJpXGo8KI",
        "colab_type": "code",
        "outputId": "22233029-33ca-42e4-df8e-1593f9a3c87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2432, 20, 5388, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTpKlzITmKb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_lstm_monster(train, ytrain, test, ytest, num_epochs, batchsize):\n",
        "    \n",
        "    #Run model\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    X_mfcc = tf.placeholder(tf.float32, [None, 20, train.shape[2]])\n",
        "    X_d = tf.placeholder(tf.float32, [None, 20, train.shape[2]])\n",
        "    X_dd = tf.placeholder(tf.float32, [None, 20, train.shape[2]])\n",
        "    y = tf.placeholder(tf.int32, [None]) \n",
        "    \n",
        "    #LSTM for MFCC\n",
        "    l1m = LSTM(NUM_HIDDEN)\n",
        "    l1m_out = l1m(X_mfcc)\n",
        "    l1m_out = tf.layers.Dropout(0.4)(l1m_out)\n",
        "    l2m = LSTM(NUM_HIDDEN, return_seq=False)\n",
        "    l2m_out = l2m(l1m_out)\n",
        "    l2m_out = tf.layers.Dropout(0.4)(l2m_out)\n",
        "    output1 = tf.layers.dense(l2m_out, 100)\n",
        "\n",
        "    #LSTM for Deltas\n",
        "    l1d = LSTM(NUM_HIDDEN)\n",
        "    l1d_out = l1d(X_d)\n",
        "    l1d_out = tf.layers.Dropout(0.4)(l1d_out)\n",
        "    l2d = LSTM(NUM_HIDDEN, return_seq=False)\n",
        "    l2d_out = l2d(l1d_out)\n",
        "    l2d_out = tf.layers.Dropout(0.4)(l2d_out)\n",
        "    output2 = tf.layers.dense(l2d_out, 100)\n",
        "\n",
        "    #LSTM for Double Deltas\n",
        "    l1dd = LSTM(NUM_HIDDEN)\n",
        "    l1dd_out = l1dd(X_dd)\n",
        "    l1dd_out = tf.layers.Dropout(0.4)(l1dd_out)\n",
        "    l2dd = LSTM(NUM_HIDDEN, return_seq=False)\n",
        "    l2dd_out = l2dd(l1dd_out)\n",
        "    l2dd_out = tf.layers.Dropout(0.4)(l2dd_out)\n",
        "    output3 = tf.layers.dense(l2dd_out, 100)\n",
        "\n",
        "\n",
        "    output_common = tf.concat([output1, output2, output3], axis=1)\n",
        "    output = tf.layers.dense(output_common, 2)\n",
        "  \n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
        "    soft_out = tf.nn.softmax(output)\n",
        "    \n",
        "    y_onehot = tf.one_hot(y, 2)\n",
        "    \n",
        "    pred = tf.equal(tf.argmax(soft_out,1), tf.argmax(y_onehot,1))\n",
        "    #pred = tf.equal(tf.argmax(soft_out,1), y)\n",
        "    accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
        "    hist = {'train_loss':[], 'test_loss':[], 'train_acc':[], 'test_acc':[]}\n",
        "    saver = tf.train.Saver()\n",
        "    with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      steps = train.shape[0]//batchsize\n",
        "      for epoch in range(num_epochs):\n",
        "          epoch_loss = 0\n",
        "          epoch_acc = 0\n",
        "          for step in range(steps):\n",
        "              start = step*batchsize\n",
        "              end = min(start + batchsize, train.shape[0])\n",
        "              batch_mfcc = train[start:end,:,:,0]\n",
        "              batch_d = train[start:end,:,:,1]\n",
        "              batch_dd = train[start:end,:,:,2]\n",
        "              batchy = ytrain[start:end]\n",
        "              _, cost = sess.run([optimizer, loss], feed_dict={X_mfcc:batch_mfcc,\n",
        "                                                               X_d:batch_d,\n",
        "                                                               X_dd:batch_dd, \n",
        "                                                              y:batchy})\n",
        "              train_acc = sess.run(accuracy, feed_dict = {X_mfcc:batch_mfcc,\n",
        "                                                          X_d:batch_d,\n",
        "                                                          X_dd:batch_dd, \n",
        "                                                          y:batchy})\n",
        "              epoch_loss += cost\n",
        "              epoch_acc += train_acc\n",
        "              \n",
        "              print(\"Epoch:\",epoch,\"Step:\",step+1,\"TrainLoss:\",epoch_loss/(step+1))\n",
        "          train_loss, train_acc = sess.run([loss,accuracy], feed_dict={X_mfcc:train[:,:,:,0],\n",
        "                                                                       X_d:train[:,:,:,1],\n",
        "                                                                       X_dd:train[:,:,:,2], \n",
        "                                                                        y:ytrain})\n",
        "          print(\"Epoch:\",epoch,\"Loss:\", train_loss, \"accuracy:\", train_acc)\n",
        "          test_loss, test_acc = sess.run([loss,accuracy], feed_dict = {X_mfcc:test[:,:,:,0],\n",
        "                                                                       X_d:test[:,:,:,1],\n",
        "                                                                       X_dd:test[:,:,:,2],\n",
        "                                                                       y:ytest})\n",
        "          print(\"Test:\",\"Epoch:\",epoch,\"Loss:\", test_loss, \"accuracy:\", test_acc)\n",
        "          hist['train_loss'].append(train_loss)\n",
        "          hist['train_acc'].append(train_acc)\n",
        "          hist['test_loss'].append(test_loss)\n",
        "          hist['test_acc'].append(test_acc)\n",
        "    return hist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm6ywTpTrAg5",
        "colab_type": "code",
        "outputId": "477f1f1c-9b2f-4f8c-9956-b101535e4fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train, ytrain, test, ytest, num_epochs, batchsize\n",
        "\n",
        "hist = run_lstm_monster(data[:1500], labels[:1500], data[1500:], labels[1500:], 10, 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Step: 1 TrainLoss: 0.7074707746505737\n",
            "Epoch: 0 Step: 2 TrainLoss: 0.6830656826496124\n",
            "Epoch: 0 Step: 3 TrainLoss: 0.6932757496833801\n",
            "Epoch: 0 Step: 4 TrainLoss: 0.6955104172229767\n",
            "Epoch: 0 Step: 5 TrainLoss: 0.6975646615028381\n",
            "Epoch: 0 Step: 6 TrainLoss: 0.7004310886065165\n",
            "Epoch: 0 Step: 7 TrainLoss: 0.7008459738322667\n",
            "Epoch: 0 Step: 8 TrainLoss: 0.7013906016945839\n",
            "Epoch: 0 Step: 9 TrainLoss: 0.7001996239026388\n",
            "Epoch: 0 Step: 10 TrainLoss: 0.7020460665225983\n",
            "Epoch: 0 Step: 11 TrainLoss: 0.7044320106506348\n",
            "Epoch: 0 Loss: 0.3929954 accuracy: 0.902\n",
            "Test: Epoch: 0 Loss: 0.7039482 accuracy: 0.54077256\n",
            "Epoch: 1 Step: 1 TrainLoss: 0.28196802735328674\n",
            "Epoch: 1 Step: 2 TrainLoss: 0.27334660291671753\n",
            "Epoch: 1 Step: 3 TrainLoss: 0.26756832003593445\n",
            "Epoch: 1 Step: 4 TrainLoss: 0.25512803345918655\n",
            "Epoch: 1 Step: 5 TrainLoss: 0.2407944142818451\n",
            "Epoch: 1 Step: 6 TrainLoss: 0.2319715271393458\n",
            "Epoch: 1 Step: 7 TrainLoss: 0.2227249549967902\n",
            "Epoch: 1 Step: 8 TrainLoss: 0.21352744475007057\n",
            "Epoch: 1 Step: 9 TrainLoss: 0.20126348071628147\n",
            "Epoch: 1 Step: 10 TrainLoss: 0.19092584326863288\n",
            "Epoch: 1 Step: 11 TrainLoss: 0.18392876400188965\n",
            "Epoch: 1 Loss: 0.077829815 accuracy: 0.9713333\n",
            "Test: Epoch: 1 Loss: 1.259824 accuracy: 0.4914163\n",
            "Epoch: 2 Step: 1 TrainLoss: 0.0023729074746370316\n",
            "Epoch: 2 Step: 2 TrainLoss: 0.004210072103887796\n",
            "Epoch: 2 Step: 3 TrainLoss: 0.006854279898107052\n",
            "Epoch: 2 Step: 4 TrainLoss: 0.006436974625103176\n",
            "Epoch: 2 Step: 5 TrainLoss: 0.005337867280468344\n",
            "Epoch: 2 Step: 6 TrainLoss: 0.005150560716477533\n",
            "Epoch: 2 Step: 7 TrainLoss: 0.004481753234618476\n",
            "Epoch: 2 Step: 8 TrainLoss: 0.00393718623672612\n",
            "Epoch: 2 Step: 9 TrainLoss: 0.0035070749654551037\n",
            "Epoch: 2 Step: 10 TrainLoss: 0.0031579432126818572\n",
            "Epoch: 2 Step: 11 TrainLoss: 0.002872357124446849\n",
            "Epoch: 2 Loss: 0.15118967 accuracy: 0.97066665\n",
            "Test: Epoch: 2 Loss: 2.8534455 accuracy: 0.49785408\n",
            "Epoch: 3 Step: 1 TrainLoss: 2.745442179730162e-05\n",
            "Epoch: 3 Step: 2 TrainLoss: 1.7662313439359423e-05\n",
            "Epoch: 3 Step: 3 TrainLoss: 2.002679138968233e-05\n",
            "Epoch: 3 Step: 4 TrainLoss: 1.5386330630917655e-05\n",
            "Epoch: 3 Step: 5 TrainLoss: 1.2683814497904678e-05\n",
            "Epoch: 3 Step: 6 TrainLoss: 1.061330695980208e-05\n",
            "Epoch: 3 Step: 7 TrainLoss: 9.142621922007623e-06\n",
            "Epoch: 3 Step: 8 TrainLoss: 8.125404637127076e-06\n",
            "Epoch: 3 Step: 9 TrainLoss: 7.36776196201087e-06\n",
            "Epoch: 3 Step: 10 TrainLoss: 6.987296708871327e-06\n",
            "Epoch: 3 Step: 11 TrainLoss: 9.719913725286295e-06\n",
            "Epoch: 3 Loss: 0.20902993 accuracy: 0.97066665\n",
            "Test: Epoch: 3 Loss: 4.0554805 accuracy: 0.51287556\n",
            "Epoch: 4 Step: 1 TrainLoss: 7.376002031378448e-05\n",
            "Epoch: 4 Step: 2 TrainLoss: 4.000253079539107e-05\n",
            "Epoch: 4 Step: 3 TrainLoss: 9.35497275046752e-05\n",
            "Epoch: 4 Step: 4 TrainLoss: 7.032387649985594e-05\n",
            "Epoch: 4 Step: 5 TrainLoss: 5.646733496860179e-05\n",
            "Epoch: 4 Step: 6 TrainLoss: 4.7063563044957846e-05\n",
            "Epoch: 4 Step: 7 TrainLoss: 4.03480466104611e-05\n",
            "Epoch: 4 Step: 8 TrainLoss: 3.534540227789762e-05\n",
            "Epoch: 4 Step: 9 TrainLoss: 3.1461079433686085e-05\n",
            "Epoch: 4 Step: 10 TrainLoss: 2.862862165216029e-05\n",
            "Epoch: 4 Step: 11 TrainLoss: 2.65057339871336e-05\n",
            "Epoch: 4 Loss: 0.23451847 accuracy: 0.97066665\n",
            "Test: Epoch: 4 Loss: 4.5438614 accuracy: 0.51287556\n",
            "Epoch: 5 Step: 1 TrainLoss: 2.21350619540317e-05\n",
            "Epoch: 5 Step: 2 TrainLoss: 1.45023082041007e-05\n",
            "Epoch: 5 Step: 3 TrainLoss: 1.268738469661912e-05\n",
            "Epoch: 5 Step: 4 TrainLoss: 9.63777246454356e-06\n",
            "Epoch: 5 Step: 5 TrainLoss: 7.825326349575334e-06\n",
            "Epoch: 5 Step: 6 TrainLoss: 6.524364917955457e-06\n",
            "Epoch: 5 Step: 7 TrainLoss: 5.597368534893121e-06\n",
            "Epoch: 5 Step: 8 TrainLoss: 4.925054926552264e-06\n",
            "Epoch: 5 Step: 9 TrainLoss: 4.4053522564190135e-06\n",
            "Epoch: 5 Step: 10 TrainLoss: 4.237305417831294e-06\n",
            "Epoch: 5 Step: 11 TrainLoss: 4.04165637878474e-06\n",
            "Epoch: 5 Loss: 0.24356905 accuracy: 0.97066665\n",
            "Test: Epoch: 5 Loss: 4.704585 accuracy: 0.5139485\n",
            "Epoch: 6 Step: 1 TrainLoss: 8.836674169288017e-06\n",
            "Epoch: 6 Step: 2 TrainLoss: 7.5085763455717824e-06\n",
            "Epoch: 6 Step: 3 TrainLoss: 6.78427901827187e-06\n",
            "Epoch: 6 Step: 4 TrainLoss: 5.182737268683013e-06\n",
            "Epoch: 6 Step: 5 TrainLoss: 4.221998210596212e-06\n",
            "Epoch: 6 Step: 6 TrainLoss: 3.5205049272827673e-06\n",
            "Epoch: 6 Step: 7 TrainLoss: 3.0219661696203763e-06\n",
            "Epoch: 6 Step: 8 TrainLoss: 2.6668048731526284e-06\n",
            "Epoch: 6 Step: 9 TrainLoss: 2.3958458054017406e-06\n",
            "Epoch: 6 Step: 10 TrainLoss: 2.3735290499260485e-06\n",
            "Epoch: 6 Step: 11 TrainLoss: 2.286697375776147e-06\n",
            "Epoch: 6 Loss: 0.24644843 accuracy: 0.97\n",
            "Test: Epoch: 6 Loss: 4.7510896 accuracy: 0.51287556\n",
            "Epoch: 7 Step: 1 TrainLoss: 4.785683813679498e-06\n",
            "Epoch: 7 Step: 2 TrainLoss: 4.827120847039623e-06\n",
            "Epoch: 7 Step: 3 TrainLoss: 4.365054564914317e-06\n",
            "Epoch: 7 Step: 4 TrainLoss: 3.358074650350318e-06\n",
            "Epoch: 7 Step: 5 TrainLoss: 2.751651379639952e-06\n",
            "Epoch: 7 Step: 6 TrainLoss: 2.294905460775709e-06\n",
            "Epoch: 7 Step: 7 TrainLoss: 1.9714523411857547e-06\n",
            "Epoch: 7 Step: 8 TrainLoss: 1.7457426441103152e-06\n",
            "Epoch: 7 Step: 9 TrainLoss: 1.5762959849002161e-06\n",
            "Epoch: 7 Step: 10 TrainLoss: 1.5815504641913946e-06\n",
            "Epoch: 7 Step: 11 TrainLoss: 1.5464824568408888e-06\n",
            "Epoch: 7 Loss: 0.2471265 accuracy: 0.97\n",
            "Test: Epoch: 7 Loss: 4.7617393 accuracy: 0.51502144\n",
            "Epoch: 8 Step: 1 TrainLoss: 3.367495537531795e-06\n",
            "Epoch: 8 Step: 2 TrainLoss: 3.6296341932029463e-06\n",
            "Epoch: 8 Step: 3 TrainLoss: 3.265033001298434e-06\n",
            "Epoch: 8 Step: 4 TrainLoss: 2.5260737288590462e-06\n",
            "Epoch: 8 Step: 5 TrainLoss: 2.079904095353413e-06\n",
            "Epoch: 8 Step: 6 TrainLoss: 1.7349608369225205e-06\n",
            "Epoch: 8 Step: 7 TrainLoss: 1.4913667608798927e-06\n",
            "Epoch: 8 Step: 8 TrainLoss: 1.3246200305516709e-06\n",
            "Epoch: 8 Step: 9 TrainLoss: 1.201240412424593e-06\n",
            "Epoch: 8 Step: 10 TrainLoss: 1.2223019744794783e-06\n",
            "Epoch: 8 Step: 11 TrainLoss: 1.2085480285215702e-06\n",
            "Epoch: 8 Loss: 0.24720575 accuracy: 0.97\n",
            "Test: Epoch: 8 Loss: 4.762079 accuracy: 0.51502144\n",
            "Epoch: 9 Step: 1 TrainLoss: 2.687698952286155e-06\n",
            "Epoch: 9 Step: 2 TrainLoss: 2.922376893366163e-06\n",
            "Epoch: 9 Step: 3 TrainLoss: 2.6330505230968506e-06\n",
            "Epoch: 9 Step: 4 TrainLoss: 2.0469647097343113e-06\n",
            "Epoch: 9 Step: 5 TrainLoss: 1.6923329098972316e-06\n",
            "Epoch: 9 Step: 6 TrainLoss: 1.4119848490423692e-06\n",
            "Epoch: 9 Step: 7 TrainLoss: 1.2145301998397632e-06\n",
            "Epoch: 9 Step: 8 TrainLoss: 1.081805971914207e-06\n",
            "Epoch: 9 Step: 9 TrainLoss: 9.85095254356515e-07\n",
            "Epoch: 9 Step: 10 TrainLoss: 1.0122190182926261e-06\n",
            "Epoch: 9 Step: 11 TrainLoss: 1.0097744759140037e-06\n",
            "Epoch: 9 Loss: 0.24718876 accuracy: 0.97\n",
            "Test: Epoch: 9 Loss: 4.7588906 accuracy: 0.5139485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOPGHCRGo8wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "model = Sequential()\n",
        "model.add(Conv2D(40 , (5,5) , input_shape = (5388, 20 ,3), name = \"Layer1\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size= (5,5), name = \"MP1\"))\n",
        "model.add(Conv2D(20 ,(2,2), name = \"Layer2\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size= (2,2), name=\"MP2\"))\n",
        "model.add(Conv2D(10, (2,1), name = \"Layer3\" ))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation=\"sigmoid\", name=\"\"))\n",
        "model.add(Dense(28, activation = \"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQkDRt4yiKMq",
        "colab_type": "code",
        "outputId": "96b70075-a8e4-40fc-d0da-9c3b2cd385b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical  \n",
        "dataSI = [(i,j) for i,j in zip(data, spkIDs)]\n",
        "np.random.shuffle(dataSI)\n",
        "dataCNN = np.array([i[0] for i in dataSI])\n",
        "y = np.array([i[1] for i in dataSI]).reshape(-1,1)\n",
        "y = to_categorical(y, num_classes=28)\n",
        "print(spkIDs.shape,y.shape, dataCNN.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2432, 1) (2432, 28) (2432, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ0q69EPE6ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=['accuracy'])\n",
        "hist = model.fit(dataCNN[:1500], y[:1500], validation_data=(dataCNN[1500:], y[1500:]), epochs=10, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfRBIZbdzVsy",
        "colab_type": "code",
        "outputId": "cafdffee-4446-4f29-d97a-9f7b1d7bbbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for layer in model.layers: print(layer.get_config(), layer.get_weights())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'Layer1', 'trainable': True, 'batch_input_shape': (None, 5388, 20, 3), 'dtype': 'float32', 'filters': 40, 'kernel_size': (5, 5), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None, 'dtype': 'float32'}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[[[ 0.00046797,  0.03231239,  0.04677802, ..., -0.01561338,\n",
            "           0.07097224,  0.00056195],\n",
            "         [-0.05607001,  0.01246016,  0.01733283, ...,  0.01473978,\n",
            "          -0.07006636, -0.06815898],\n",
            "         [ 0.01064105,  0.03229722,  0.04271815, ...,  0.04024877,\n",
            "          -0.06826036,  0.04488011]],\n",
            "\n",
            "        [[ 0.05024427, -0.02644952,  0.02171575, ..., -0.03840618,\n",
            "           0.00394654, -0.04848399],\n",
            "         [ 0.05738831, -0.04601452, -0.03712133, ..., -0.06476265,\n",
            "           0.01594223, -0.07240032],\n",
            "         [-0.04182574,  0.02261624,  0.06211717, ...,  0.02164717,\n",
            "           0.05408765, -0.00772018]],\n",
            "\n",
            "        [[-0.07336336,  0.00504183,  0.06718632, ...,  0.04640799,\n",
            "           0.02586559, -0.00244934],\n",
            "         [-0.03075363,  0.03468993,  0.02394781, ...,  0.02327933,\n",
            "          -0.05107023, -0.03079191],\n",
            "         [-0.05575899,  0.00921343, -0.04588383, ..., -0.05530641,\n",
            "           0.00863016, -0.06069634]],\n",
            "\n",
            "        [[ 0.05921026,  0.06694526, -0.01963792, ..., -0.04751129,\n",
            "           0.06094492,  0.00720228],\n",
            "         [ 0.07337899,  0.00444351,  0.04325579, ...,  0.05661344,\n",
            "          -0.05873659,  0.02747351],\n",
            "         [-0.04173082, -0.05520237,  0.0293493 , ..., -0.04082612,\n",
            "           0.06201521, -0.00337385]],\n",
            "\n",
            "        [[ 0.00370084,  0.04708563, -0.02611838, ...,  0.07288869,\n",
            "          -0.06809603, -0.07091041],\n",
            "         [ 0.04255163,  0.06168405, -0.04870917, ..., -0.01583295,\n",
            "          -0.00083825,  0.05901247],\n",
            "         [-0.00524286, -0.0383453 , -0.01282516, ..., -0.00350094,\n",
            "          -0.03207548,  0.03319634]]],\n",
            "\n",
            "\n",
            "       [[[ 0.03116561, -0.01945128, -0.05035114, ...,  0.04670627,\n",
            "          -0.03724337, -0.06112723],\n",
            "         [ 0.06359041, -0.0523835 ,  0.03934443, ...,  0.04002093,\n",
            "           0.05417284, -0.06151897],\n",
            "         [ 0.03222162,  0.04412336,  0.06162808, ...,  0.04732833,\n",
            "          -0.0448097 ,  0.04242709]],\n",
            "\n",
            "        [[-0.07025302, -0.05218866, -0.04725831, ...,  0.06485272,\n",
            "           0.00260473, -0.02299104],\n",
            "         [-0.04868136, -0.07199223,  0.04287487, ...,  0.03339315,\n",
            "          -0.07375715,  0.03203998],\n",
            "         [ 0.03622147, -0.06609408,  0.03692661, ...,  0.05794803,\n",
            "          -0.07435485,  0.07173976]],\n",
            "\n",
            "        [[ 0.01879837, -0.00052508, -0.0309332 , ...,  0.0051284 ,\n",
            "           0.04687071,  0.02929582],\n",
            "         [ 0.04430328,  0.01708041, -0.06396849, ..., -0.00480314,\n",
            "          -0.07386367, -0.01545653],\n",
            "         [ 0.05768026,  0.03394376, -0.04766672, ..., -0.01572841,\n",
            "          -0.05361605, -0.03029875]],\n",
            "\n",
            "        [[-0.06265637,  0.00048774,  0.0137466 , ..., -0.0698349 ,\n",
            "          -0.05993097, -0.05056011],\n",
            "         [-0.07268511, -0.00620887, -0.05699316, ..., -0.05223134,\n",
            "           0.05731169, -0.00546248],\n",
            "         [-0.04516368,  0.00110409,  0.07180559, ...,  0.00784853,\n",
            "           0.06877661, -0.02931176]],\n",
            "\n",
            "        [[ 0.04495306,  0.04384841, -0.06949988, ..., -0.05341993,\n",
            "           0.00406232, -0.01863144],\n",
            "         [-0.01106375,  0.01859507,  0.00422239, ..., -0.02755913,\n",
            "          -0.00333342, -0.04394764],\n",
            "         [ 0.00867718, -0.04740781, -0.07135747, ..., -0.04530185,\n",
            "           0.06740231, -0.04877121]]],\n",
            "\n",
            "\n",
            "       [[[-0.02275213, -0.05095531, -0.05259773, ...,  0.02702438,\n",
            "          -0.03642432,  0.03289388],\n",
            "         [-0.06534971, -0.05883289,  0.01432321, ..., -0.00639964,\n",
            "           0.01241183, -0.03439999],\n",
            "         [ 0.0215575 , -0.05321324,  0.0110878 , ..., -0.0161471 ,\n",
            "           0.01274363,  0.01647465]],\n",
            "\n",
            "        [[-0.06592873,  0.0516051 , -0.05113232, ..., -0.00316253,\n",
            "           0.01545575, -0.06296017],\n",
            "         [-0.04906534,  0.06318294,  0.07100766, ...,  0.04906096,\n",
            "           0.0245541 , -0.0496664 ],\n",
            "         [ 0.07090203,  0.01814712, -0.025794  , ..., -0.05831715,\n",
            "           0.03734428, -0.07462778]],\n",
            "\n",
            "        [[-0.02497309, -0.01261931, -0.04356365, ..., -0.03523482,\n",
            "          -0.06608959, -0.06569552],\n",
            "         [-0.06545179, -0.02290353,  0.07331545, ..., -0.00738169,\n",
            "          -0.01994115,  0.02637824],\n",
            "         [-0.03791222, -0.04078436,  0.01100529, ...,  0.04865041,\n",
            "          -0.04837195, -0.07219218]],\n",
            "\n",
            "        [[ 0.01806135,  0.05659334, -0.06547718, ..., -0.06250176,\n",
            "           0.01080979,  0.0278727 ],\n",
            "         [-0.01953335,  0.01316618, -0.00596382, ..., -0.06560487,\n",
            "           0.00805657,  0.00969283],\n",
            "         [-0.03388663, -0.04398866, -0.02270091, ...,  0.02690264,\n",
            "           0.04098038, -0.00084464]],\n",
            "\n",
            "        [[-0.07091661, -0.01461029,  0.05665985, ..., -0.05319858,\n",
            "           0.02896228,  0.0442178 ],\n",
            "         [ 0.00528283, -0.02922555,  0.00799723, ..., -0.07053317,\n",
            "          -0.06712727,  0.02128136],\n",
            "         [ 0.02972797,  0.05824933, -0.05862708, ...,  0.06438797,\n",
            "           0.05503196,  0.02532265]]],\n",
            "\n",
            "\n",
            "       [[[ 0.04119322, -0.07119553, -0.06353642, ..., -0.00592755,\n",
            "           0.01425605,  0.06537785],\n",
            "         [-0.03117854,  0.02841584,  0.05919567, ..., -0.01411113,\n",
            "          -0.01411476, -0.06617819],\n",
            "         [ 0.02184978,  0.01718933, -0.03565559, ...,  0.02433531,\n",
            "           0.02753592, -0.00372106]],\n",
            "\n",
            "        [[-0.00783352, -0.05915201,  0.03833582, ...,  0.01693975,\n",
            "           0.06183898,  0.04455804],\n",
            "         [-0.04924629,  0.05300873, -0.01015196, ..., -0.01533118,\n",
            "          -0.05445886, -0.00766904],\n",
            "         [ 0.07369552,  0.01805373, -0.04581011, ..., -0.06558731,\n",
            "           0.0629657 , -0.01655503]],\n",
            "\n",
            "        [[-0.0406069 , -0.03016276, -0.06677688, ..., -0.03434903,\n",
            "          -0.05699837,  0.01073099],\n",
            "         [ 0.03284552, -0.01675723,  0.05031025, ..., -0.03994473,\n",
            "           0.04542261, -0.05946139],\n",
            "         [-0.02714492, -0.00912639,  0.03067524, ...,  0.05546976,\n",
            "           0.01603742, -0.05255985]],\n",
            "\n",
            "        [[ 0.04268217, -0.04667918, -0.05674539, ..., -0.01612625,\n",
            "          -0.03719048, -0.00891068],\n",
            "         [-0.06072287, -0.06976047,  0.05376486, ..., -0.05911298,\n",
            "          -0.04635184, -0.0690639 ],\n",
            "         [ 0.03343861,  0.0701851 ,  0.04580892, ...,  0.03505499,\n",
            "           0.07417884, -0.06310183]],\n",
            "\n",
            "        [[-0.06320377,  0.05415315, -0.05026215, ..., -0.01854032,\n",
            "           0.06354574,  0.0142725 ],\n",
            "         [ 0.06746954, -0.06252459, -0.00957759, ...,  0.06220471,\n",
            "           0.00965242,  0.00686751],\n",
            "         [-0.02115636,  0.01039607, -0.06987472, ..., -0.0021885 ,\n",
            "           0.05540217,  0.06747714]]],\n",
            "\n",
            "\n",
            "       [[[ 0.02878757, -0.07466596, -0.0420981 , ...,  0.01071316,\n",
            "          -0.05411178,  0.00037286],\n",
            "         [ 0.04193172,  0.04739431,  0.07102104, ..., -0.02411095,\n",
            "           0.07366415, -0.01887614],\n",
            "         [-0.0145519 , -0.03975872,  0.02845958, ..., -0.03471756,\n",
            "           0.03456724, -0.0201953 ]],\n",
            "\n",
            "        [[ 0.05329903, -0.06823356,  0.01418435, ..., -0.05122773,\n",
            "           0.02892212,  0.01683132],\n",
            "         [-0.00859956, -0.00165708,  0.03041143, ..., -0.06620587,\n",
            "          -0.03094939, -0.008522  ],\n",
            "         [ 0.0602622 , -0.0612662 , -0.0674584 , ..., -0.07384117,\n",
            "          -0.02302836, -0.03635453]],\n",
            "\n",
            "        [[-0.02956086,  0.00983188, -0.01488406, ..., -0.04165033,\n",
            "           0.07441726, -0.0102716 ],\n",
            "         [-0.01358083,  0.02616479,  0.05604172, ...,  0.04795426,\n",
            "          -0.06556303, -0.01201594],\n",
            "         [ 0.01051986,  0.00416345,  0.00314096, ...,  0.02524976,\n",
            "          -0.04325869,  0.01654552]],\n",
            "\n",
            "        [[ 0.06165912, -0.03899013,  0.02112319, ...,  0.04021965,\n",
            "           0.01220017, -0.07221943],\n",
            "         [-0.06111701, -0.06669229,  0.03370555, ...,  0.01667493,\n",
            "           0.03741015, -0.0402699 ],\n",
            "         [ 0.01254604, -0.04900964,  0.03799666, ...,  0.06120453,\n",
            "           0.03219979, -0.0265457 ]],\n",
            "\n",
            "        [[ 0.06305262, -0.01390864,  0.01829068, ...,  0.00488798,\n",
            "           0.04462977,  0.02166437],\n",
            "         [ 0.031777  , -0.01872579,  0.04097492, ..., -0.04848254,\n",
            "           0.03257857, -0.04502061],\n",
            "         [ 0.00271894,  0.04875226,  0.01491877, ..., -0.05840307,\n",
            "           0.04094889, -0.04848552]]]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
            "{'name': 'activation_6', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} []\n",
            "{'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None} []\n",
            "{'name': 'MP1', 'trainable': True, 'dtype': 'float32', 'pool_size': (5, 5), 'padding': 'valid', 'strides': (5, 5), 'data_format': 'channels_last'} []\n",
            "{'name': 'Layer2', 'trainable': True, 'dtype': 'float32', 'filters': 20, 'kernel_size': (2, 2), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None, 'dtype': 'float32'}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[[[-0.12074358,  0.0140278 ,  0.03724632, ..., -0.00375065,\n",
            "           0.14635648, -0.10759729],\n",
            "         [ 0.14386834, -0.04157694, -0.02496578, ..., -0.11329196,\n",
            "           0.11998241, -0.04180595],\n",
            "         [-0.06238487, -0.06840093,  0.08914545, ..., -0.08219712,\n",
            "           0.15056454, -0.07410567],\n",
            "         ...,\n",
            "         [-0.11368529, -0.06742167, -0.04263394, ..., -0.09169511,\n",
            "          -0.09474523,  0.01185769],\n",
            "         [-0.01715086,  0.07952514,  0.07668318, ..., -0.10704729,\n",
            "           0.00758518,  0.14941822],\n",
            "         [-0.10623163, -0.0143811 ,  0.041741  , ...,  0.0961936 ,\n",
            "          -0.03201412, -0.02143596]],\n",
            "\n",
            "        [[ 0.02858566, -0.00135487,  0.02343784, ..., -0.07658309,\n",
            "           0.1288471 ,  0.07909253],\n",
            "         [-0.00088483, -0.10802124,  0.01368472, ...,  0.0704174 ,\n",
            "           0.12640156,  0.12249507],\n",
            "         [ 0.1475765 ,  0.10094105, -0.05420798, ..., -0.05322465,\n",
            "           0.12420206, -0.0128918 ],\n",
            "         ...,\n",
            "         [ 0.02067082,  0.07947539, -0.01027171, ..., -0.09900333,\n",
            "          -0.02619739, -0.08871574],\n",
            "         [ 0.13356476,  0.03449954, -0.11473772, ..., -0.11841992,\n",
            "          -0.06426411,  0.04536551],\n",
            "         [-0.06839687,  0.07457861, -0.0678616 , ...,  0.06456332,\n",
            "           0.02081142, -0.00688583]]],\n",
            "\n",
            "\n",
            "       [[[-0.10795493,  0.03891291,  0.09430511, ...,  0.15428872,\n",
            "          -0.08286557, -0.0699814 ],\n",
            "         [-0.1223021 , -0.06558212,  0.13976283, ..., -0.05205535,\n",
            "          -0.15047678, -0.06827344],\n",
            "         [ 0.0213033 , -0.01285146,  0.00606859, ..., -0.07265345,\n",
            "           0.04473692, -0.02219436],\n",
            "         ...,\n",
            "         [ 0.06970753, -0.14180076, -0.13545781, ...,  0.1374103 ,\n",
            "           0.11051835, -0.06621547],\n",
            "         [ 0.06915055,  0.09616201,  0.02937433, ..., -0.03075412,\n",
            "          -0.05612666,  0.15675537],\n",
            "         [-0.04235535,  0.05181707, -0.00619867, ..., -0.02894582,\n",
            "          -0.01431276,  0.13764681]],\n",
            "\n",
            "        [[-0.10143183,  0.03847057, -0.12693381, ..., -0.05859587,\n",
            "          -0.0531462 ,  0.15713628],\n",
            "         [ 0.02969098,  0.05253226, -0.1145878 , ...,  0.1504711 ,\n",
            "          -0.0948313 ,  0.11199458],\n",
            "         [-0.07576028, -0.02212457,  0.00532877, ...,  0.06554413,\n",
            "           0.04352318, -0.02422665],\n",
            "         ...,\n",
            "         [-0.13998847,  0.01619117,  0.13630791, ..., -0.14343554,\n",
            "           0.01734373, -0.06967827],\n",
            "         [-0.06751064,  0.0740757 , -0.08298209, ...,  0.09838577,\n",
            "          -0.13083187,  0.05476806],\n",
            "         [-0.00493507,  0.04790401,  0.08837597, ...,  0.04563068,\n",
            "          -0.05589893,  0.12177952]]]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.], dtype=float32)]\n",
            "{'name': 'activation_7', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} []\n",
            "{'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None} []\n",
            "{'name': 'MP2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'} []\n",
            "{'name': 'Layer3', 'trainable': True, 'dtype': 'float32', 'filters': 10, 'kernel_size': (2, 1), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None, 'dtype': 'float32'}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[[[ 0.17222857,  0.04533249,  0.19855854,  0.09866595,\n",
            "          -0.29407504,  0.18732157, -0.2042534 , -0.08525853,\n",
            "          -0.29876396, -0.13579755],\n",
            "         [-0.30258375, -0.12324148,  0.14366677,  0.18454048,\n",
            "          -0.12592643, -0.28541362,  0.1413278 , -0.2728688 ,\n",
            "           0.18095797, -0.2691023 ],\n",
            "         [ 0.0848771 ,  0.044314  ,  0.167211  ,  0.2300637 ,\n",
            "          -0.1144553 ,  0.0267019 , -0.00657183,  0.05437222,\n",
            "          -0.28924397,  0.28800014],\n",
            "         [-0.19930503, -0.20806625,  0.15077588,  0.25461552,\n",
            "           0.03396639,  0.01304996, -0.24709433, -0.08510418,\n",
            "          -0.27664366,  0.12963471],\n",
            "         [-0.30585656,  0.03077507,  0.11998466,  0.2345337 ,\n",
            "           0.1049853 , -0.01721355,  0.18132645, -0.08599566,\n",
            "          -0.3015927 ,  0.12735668],\n",
            "         [-0.27792105, -0.10078159,  0.15895528, -0.29411733,\n",
            "          -0.2560833 , -0.00123882,  0.16332969,  0.1867195 ,\n",
            "           0.04286325, -0.02008376],\n",
            "         [-0.08297558,  0.21051756,  0.11392316,  0.31599805,\n",
            "          -0.16195358,  0.09956223, -0.09865011, -0.13300832,\n",
            "           0.22578982,  0.01558632],\n",
            "         [ 0.08457825,  0.17738074, -0.15931506, -0.11728026,\n",
            "           0.293299  ,  0.07646579,  0.25414672,  0.02105281,\n",
            "          -0.13972779,  0.22950092],\n",
            "         [ 0.13176054,  0.07985988,  0.21856067,  0.08919579,\n",
            "          -0.01553151,  0.07148069, -0.20190063, -0.02079555,\n",
            "           0.12782976, -0.0243434 ],\n",
            "         [-0.10628389, -0.05080578, -0.21742582, -0.08873293,\n",
            "          -0.03900409, -0.2630479 ,  0.01376608, -0.03670442,\n",
            "          -0.20750177, -0.08827755],\n",
            "         [-0.09381957, -0.27998763,  0.05556664, -0.20802772,\n",
            "           0.15686852, -0.22164428, -0.22376952, -0.09575948,\n",
            "           0.09990579, -0.05445161],\n",
            "         [-0.12041637,  0.20958254, -0.23172432,  0.12679732,\n",
            "          -0.0123314 , -0.23268779, -0.09896262,  0.27445462,\n",
            "           0.25902393,  0.29695323],\n",
            "         [ 0.02914912, -0.29295528, -0.28776556, -0.10899122,\n",
            "          -0.25212044, -0.15111697, -0.02902117,  0.28557608,\n",
            "           0.21614024, -0.30067998],\n",
            "         [ 0.04086226,  0.30285624, -0.21750799, -0.3145546 ,\n",
            "          -0.1914312 ,  0.24441323,  0.12644169,  0.01496121,\n",
            "           0.22532293, -0.15892121],\n",
            "         [-0.06617767, -0.10354601, -0.24866366, -0.00420627,\n",
            "           0.00350428, -0.29105857,  0.09204817, -0.01094088,\n",
            "          -0.28835672,  0.31453106],\n",
            "         [-0.21452086,  0.02792343, -0.3077445 , -0.29894078,\n",
            "           0.30997363,  0.05313924,  0.08231941, -0.21092257,\n",
            "           0.15576512, -0.2231037 ],\n",
            "         [-0.2107877 ,  0.14685988, -0.22541583,  0.10233223,\n",
            "          -0.14171043, -0.02839497, -0.21613288, -0.19437182,\n",
            "          -0.19380236,  0.24479595],\n",
            "         [-0.29829922,  0.19893584, -0.13423325, -0.08703926,\n",
            "          -0.27495557, -0.29303384, -0.08995372, -0.2002366 ,\n",
            "          -0.06951086, -0.31466115],\n",
            "         [-0.06419367,  0.06711444,  0.14038387,  0.28414813,\n",
            "           0.02032396, -0.03951135,  0.25764468,  0.05002716,\n",
            "           0.29890814,  0.08442527],\n",
            "         [ 0.25503525,  0.0796006 , -0.19910245,  0.24582544,\n",
            "          -0.08938751,  0.20043686, -0.07308765,  0.12630981,\n",
            "          -0.23352844,  0.18951747]]],\n",
            "\n",
            "\n",
            "       [[[ 0.26639912, -0.26814014,  0.10997015,  0.03521031,\n",
            "           0.03863272, -0.06261277,  0.07213014,  0.29895946,\n",
            "           0.3139868 ,  0.21862027],\n",
            "         [-0.31063122, -0.18936034,  0.19691011, -0.2477961 ,\n",
            "           0.19197616,  0.17899117,  0.2311835 ,  0.23850486,\n",
            "           0.21441016,  0.0805285 ],\n",
            "         [-0.25116366, -0.1599468 , -0.1574713 , -0.10146511,\n",
            "          -0.15338604, -0.06984025, -0.12120107,  0.06130272,\n",
            "          -0.1805654 , -0.26793852],\n",
            "         [-0.07132138,  0.3079302 ,  0.10317311, -0.11250401,\n",
            "          -0.27438822,  0.1989598 ,  0.02256063, -0.15564772,\n",
            "          -0.24479224,  0.22981444],\n",
            "         [ 0.2581875 ,  0.02359399, -0.1920419 ,  0.10527781,\n",
            "          -0.18419407,  0.19610116,  0.22935095,  0.14600077,\n",
            "           0.11048818, -0.09050734],\n",
            "         [ 0.04139125, -0.20617047, -0.18460783,  0.08409375,\n",
            "          -0.26064938,  0.02476409,  0.08001837, -0.09876554,\n",
            "          -0.00805402, -0.02565759],\n",
            "         [ 0.28845534,  0.0854477 ,  0.26239982,  0.24396297,\n",
            "          -0.2054417 ,  0.14568749,  0.17766914, -0.07275961,\n",
            "           0.0700472 ,  0.2570599 ],\n",
            "         [ 0.24020079, -0.18717058,  0.19992837,  0.19396123,\n",
            "           0.18914804, -0.2378456 ,  0.17733678,  0.10657626,\n",
            "          -0.0753957 , -0.27724695],\n",
            "         [ 0.02663374,  0.18133119, -0.15845014, -0.29981136,\n",
            "          -0.16057062,  0.11288768, -0.08001882, -0.06797597,\n",
            "          -0.03551438,  0.30142352],\n",
            "         [-0.01231796, -0.13225317,  0.2927049 , -0.04645106,\n",
            "          -0.13451643, -0.2359967 ,  0.11261681,  0.3042138 ,\n",
            "          -0.26379687, -0.02423212],\n",
            "         [-0.14281218, -0.25495782,  0.23444226, -0.21934694,\n",
            "           0.24942973, -0.05709103,  0.2865148 ,  0.14206019,\n",
            "          -0.3038003 ,  0.24203518],\n",
            "         [ 0.10909075, -0.11794192, -0.19464429,  0.28375944,\n",
            "          -0.21204868, -0.14176713, -0.13306524, -0.01383996,\n",
            "           0.29427692,  0.04655427],\n",
            "         [-0.02704185,  0.1485565 ,  0.17486739, -0.28311953,\n",
            "           0.09860322,  0.29053667, -0.11291754, -0.31099507,\n",
            "          -0.02162725, -0.21425086],\n",
            "         [ 0.24217281,  0.13336939, -0.09078141,  0.26345888,\n",
            "           0.05830148,  0.22855082,  0.10115117, -0.05002227,\n",
            "          -0.05778202, -0.2972409 ],\n",
            "         [ 0.12379217,  0.19254377,  0.0422273 ,  0.02205193,\n",
            "          -0.00168604, -0.04701763, -0.24413902, -0.06097484,\n",
            "           0.05396691, -0.08899756],\n",
            "         [ 0.14816925, -0.27344957,  0.2515196 , -0.211126  ,\n",
            "           0.0339762 , -0.28464422,  0.31082854,  0.284888  ,\n",
            "           0.08433291, -0.0268456 ],\n",
            "         [ 0.11503968,  0.22058502, -0.09775577, -0.20694001,\n",
            "          -0.17182694, -0.13867   ,  0.08334124, -0.03721455,\n",
            "           0.2664477 ,  0.03149864],\n",
            "         [ 0.08955625,  0.31472638,  0.13838193,  0.2017099 ,\n",
            "          -0.02225217,  0.16616732,  0.3088301 , -0.2557307 ,\n",
            "           0.25399837,  0.08920935],\n",
            "         [ 0.31232378, -0.11193991, -0.0559305 , -0.31137016,\n",
            "           0.01488727, -0.08116595, -0.2527319 ,  0.04060051,\n",
            "           0.11965692, -0.02029434],\n",
            "         [ 0.08255479,  0.30202094,  0.09001517, -0.24028386,\n",
            "          -0.20076293,  0.10399097,  0.09778866, -0.14936283,\n",
            "          -0.31017855,  0.18827584]]]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
            "{'name': 'activation_8', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} []\n",
            "{'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None} []\n",
            "{'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} []\n",
            "{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None, 'dtype': 'float32'}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[ 8.9634620e-03,  3.1010974e-02, -1.3549412e-02, ...,\n",
            "        -1.5340345e-02,  2.6696615e-02,  2.3127567e-02],\n",
            "       [-8.8605732e-03,  3.8945526e-03, -1.4220513e-03, ...,\n",
            "        -2.4890181e-02, -2.6948545e-02,  3.2687601e-02],\n",
            "       [-1.8488647e-02, -3.1387191e-02,  1.1988021e-02, ...,\n",
            "         2.1289583e-02, -3.0712642e-02, -1.1799857e-03],\n",
            "       ...,\n",
            "       [-2.2803023e-03,  6.1970204e-05,  1.3977103e-02, ...,\n",
            "         2.2223026e-02,  3.5148747e-03,  2.2708997e-04],\n",
            "       [-2.5060762e-02, -1.9091321e-02,  1.4729403e-02, ...,\n",
            "        -1.6636336e-02,  1.6067922e-04, -4.2594559e-03],\n",
            "       [-2.2128826e-02, -6.5213740e-03,  4.5315437e-03, ...,\n",
            "        -8.3988663e-03, -8.9519229e-03, -2.5142707e-02]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "      dtype=float32)]\n",
            "{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 28, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None, 'dtype': 'float32'}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[ 0.10481431, -0.19073611, -0.19300967, ..., -0.09406808,\n",
            "        -0.18203649,  0.04722248],\n",
            "       [ 0.03168429,  0.15614815, -0.09706163, ...,  0.17846496,\n",
            "         0.15623863, -0.04421437],\n",
            "       [-0.20689997,  0.17907451,  0.09949361, ..., -0.01547138,\n",
            "         0.16098358, -0.10744843],\n",
            "       ...,\n",
            "       [-0.02476516,  0.17046578,  0.09778388, ...,  0.13101457,\n",
            "         0.14708088,  0.02825952],\n",
            "       [ 0.00167556,  0.14324652,  0.19215445, ..., -0.09316061,\n",
            "        -0.01948509,  0.05714516],\n",
            "       [ 0.19709884, -0.17572202,  0.15246408, ..., -0.16609159,\n",
            "        -0.11555893, -0.06937219]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkcC8mIDTuDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def trainCNN(train, test, ytrain, ytest, num_epochs, batchsize):\n",
        "  X = tf.placeholder(tf.float32, [None, 5388, 20, 3])\n",
        "  y = tf.placeholder(tf.float32, [None, 2])\n",
        "\n",
        "  layer1 = tf.nn.conv2d(X, np.random.rand(10,10,3,64), strides = [1,1,1,1], padding = 'VALID')\n",
        "  act1 = tf.nn.relu(layer1)\n",
        "  out1 = tf.nn.max_pool2d(act1, ksize=[5,5,3,3], strides = [1,1,1,1], padding = \"VALID\")\n",
        "\n",
        "  layer2 = tf.nn.conv2d(out1, np.random.rand(5,5,3,32), strides = [1,1,1,1], padding = 'VALID')\n",
        "  act2 = tf.nn.relu(layer2)\n",
        "  out2 = tf.nn.max_pool2d(act1, [5,5,3,1], padding = \"VALID\")\n",
        "\n",
        "  layer3 = tf.nn.conv2d(out2, np.random.rand(3,3,1,28), strides = [1,1,1,1], padding = 'VALID')\n",
        "  act3 = tf.nn.relu(layer3)\n",
        "  out3 = tf.nn.max_pool2d(act1, ksize=[5,5,3,1], strides = [1,1,1,1], padding = \"VALID\")\n",
        "\n",
        "  layer4 = tf.nn.conv2d(out3, np.random.rand(3,3,3,16), strides = [1,1,1,1], padding = 'VALID')\n",
        "  act4 = tf.nn.relu(layer4)\n",
        "  out4 = tf.nn.max_pool2d(act1, ksize=[5,5,3,1], strides = [1,1,1,1], padding = \"VALID\")\n",
        "\n",
        "  layer5 = tf.nn.conv2d(out4, np.random.rand(3,3,3,8), strides = [1,1,1,1], padding = 'VALID')\n",
        "  act5 = tf.nn.relu(layer5)\n",
        "  out5 = tf.nn.max_pool2d(act1, ksize=[5,5,3,1], strides = [1,1,1,1], padding = \"VALID\")\n",
        "  print(out5.get_shape())\n",
        "\n",
        "  out6 = tf.nn.relu(tf.reshape(out5, [-1, 2]))\n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
        "  loss = tf.reduce_mean(loss)\n",
        "\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\n",
        "\n",
        "  soft_out = tf.nn.softmax(output)\n",
        "\n",
        "  y_onehot = tf.one_hot(y, 2)\n",
        "\n",
        "  pred = tf.equal(tf.argmax(soft_out,1), tf.argmax(y_onehot,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
        "  hist = {'train_loss':[], 'val_loss':[], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      steps = data.shape[0]//batchsize\n",
        "      for epoch in range(num_epochs):\n",
        "          epoch_loss = 0\n",
        "          epoch_acc = 0\n",
        "          for step in range(steps):\n",
        "              start = step*batchsize\n",
        "              end = min(start + batchsize, mfcc.shape[0])\n",
        "              batch_mfcc = train[start:end]\n",
        "              #batch_pitch = pitches[start:end]\n",
        "              batchy = ytrain[start:end]\n",
        "              _, cost = sess.run([optimizer, loss], feed_dict={X:batch_mfcc, \n",
        "                                                                y:batchy})\n",
        "              train_acc = sess.run(accuracy, feed_dict = {X:batch_mfcc, \n",
        "                                                          y:batchy})\n",
        "              hist['train_loss'].append(cost)\n",
        "              hist['train_acc'].append(train_acc)\n",
        "              epoch_loss += cost\n",
        "              epoch_acc += train_acc\n",
        "              if (step+1)%5==0:\n",
        "                print(\"Epoch:\",epoch,\"Step:\",step+1,\"TrainLoss:\",epoch_loss/(step+1))\n",
        "          print(\"Epoch:\",epoch,\"Loss:\", epoch_loss/(steps+1), \"accuracy:\", epoch_acc/(steps+1))\n",
        "          test_loss, test_acc = sess.run([loss,accuracy], feed_dict = {X:test, y:ytest})\n",
        "          print(\"Test:\",\"Epoch:\",epoch,\"Loss:\", test_loss, \"accuracy:\", test_acc)\n",
        "  return hist\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQt7Z1xyUgl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = trainCNN(data[:1700,:,:,:], data[1700:,:,:,:], labels[:1700], labels[1700:], num_epochs=10, batchsize = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Jk05IcOaMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9BVAaekEjQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model.load_weights('drive/My Drive/Models/embeds.h5', by_name=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCvvsMaLEuLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = np.load('drive/My Drive/SiameseDataset.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPhhIRX_FYPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}